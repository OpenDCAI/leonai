{
  "models": {
    "aion-1.0": {
      "cache_read": "2.0000000",
      "cache_write": "4.0000000",
      "input": "4.000000",
      "output": "8.000000"
    },
    "aion-1.0-mini": {
      "cache_read": "0.35000000",
      "cache_write": "0.70000000",
      "input": "0.7000000",
      "output": "1.4000000"
    },
    "aion-rp-llama-3.1-8b": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "1.6000000"
    },
    "auto": {
      "cache_read": "-500000.0",
      "cache_write": "-1000000.0",
      "input": "-1000000",
      "output": "-1000000"
    },
    "bodybuilder": {
      "cache_read": "-500000.0",
      "cache_write": "-1000000.0",
      "input": "-1000000",
      "output": "-1000000"
    },
    "claude-3-haiku": {
      "cache_read": "0.03000000",
      "cache_write": "0.3000000",
      "input": "0.25000000",
      "output": "1.25000000"
    },
    "claude-3.5-haiku": {
      "cache_read": "0.08000000",
      "cache_write": "1.000000",
      "input": "0.8000000",
      "output": "4.000000"
    },
    "claude-3.5-sonnet": {
      "cache_read": "0.6000000",
      "cache_write": "7.5000000",
      "input": "6.000000",
      "output": "30.00000"
    },
    "claude-3.7-sonnet": {
      "cache_read": "0.3000000",
      "cache_write": "3.75000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "claude-3.7-sonnet:thinking": {
      "cache_read": "0.3000000",
      "cache_write": "3.75000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "claude-haiku-4.5": {
      "cache_read": "0.1000000",
      "cache_write": "1.25000000",
      "input": "1.000000",
      "output": "5.000000"
    },
    "claude-opus-4": {
      "cache_read": "1.5000000",
      "cache_write": "18.75000000",
      "input": "15.000000",
      "output": "75.000000"
    },
    "claude-opus-4.1": {
      "cache_read": "1.5000000",
      "cache_write": "18.75000000",
      "input": "15.000000",
      "output": "75.000000"
    },
    "claude-opus-4.5": {
      "cache_read": "0.5000000",
      "cache_write": "6.25000000",
      "input": "5.000000",
      "output": "25.000000"
    },
    "claude-opus-4.6": {
      "cache_read": "0.5000000",
      "cache_write": "6.25000000",
      "input": "5.000000",
      "output": "25.000000"
    },
    "claude-sonnet-4": {
      "cache_read": "0.3000000",
      "cache_write": "3.75000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "claude-sonnet-4.5": {
      "cache_read": "0.3000000",
      "cache_write": "3.75000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "claude-sonnet-4.6": {
      "cache_read": "0.3000000",
      "cache_write": "3.75000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "codellama-7b-instruct-solidity": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "1.2000000"
    },
    "coder-large": {
      "cache_read": "0.25000000",
      "cache_write": "0.50000000",
      "input": "0.5000000",
      "output": "0.8000000"
    },
    "codestral-2508": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.9000000"
    },
    "cogito-v2.1-671b": {
      "cache_read": "0.625000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "1.25000000"
    },
    "command-a": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "command-r-08-2024": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "command-r-plus-08-2024": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "command-r7b-12-2024": {
      "cache_read": "0.01875000000",
      "cache_write": "0.03750000000",
      "input": "0.0375000000",
      "output": "0.15000000"
    },
    "cydonia-24b-v4.1": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.5000000"
    },
    "deepseek-chat": {
      "cache_read": "0.032000000",
      "cache_write": "0.320000000",
      "input": "0.32000000",
      "output": "0.89000000"
    },
    "deepseek-chat-v3-0324": {
      "cache_read": "0.095000000",
      "cache_write": "0.190000000",
      "input": "0.19000000",
      "output": "0.87000000"
    },
    "deepseek-chat-v3.1": {
      "cache_read": "0.015000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.75000000"
    },
    "deepseek-r1": {
      "cache_read": "0.07000000",
      "cache_write": "0.70000000",
      "input": "0.7000000",
      "output": "2.5000000"
    },
    "deepseek-r1-0528": {
      "cache_read": "0.2000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.75000000"
    },
    "deepseek-r1-distill-llama-70b": {
      "cache_read": "0.07000000",
      "cache_write": "0.70000000",
      "input": "0.7000000",
      "output": "0.8000000"
    },
    "deepseek-r1-distill-qwen-32b": {
      "cache_read": "0.029000000",
      "cache_write": "0.290000000",
      "input": "0.29000000",
      "output": "0.29000000"
    },
    "deepseek-r1t2-chimera": {
      "cache_read": "0.125000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "0.85000000"
    },
    "deepseek-v3.1-nex-n1": {
      "cache_read": "0.135000000",
      "cache_write": "0.270000000",
      "input": "0.27000000",
      "output": "1.000000"
    },
    "deepseek-v3.1-terminus": {
      "cache_read": "0.1300000002000000",
      "cache_write": "0.210000000",
      "input": "0.21000000",
      "output": "0.79000000"
    },
    "deepseek-v3.1-terminus:exacto": {
      "cache_read": "0.168000000",
      "cache_write": "0.210000000",
      "input": "0.21000000",
      "output": "0.79000000"
    },
    "deepseek-v3.2": {
      "cache_read": "0.13000000",
      "cache_write": "0.260000000",
      "input": "0.26000000",
      "output": "0.38000000"
    },
    "deepseek-v3.2-exp": {
      "cache_read": "0.027000000",
      "cache_write": "0.270000000",
      "input": "0.27000000",
      "output": "0.41000000"
    },
    "deepseek-v3.2-speciale": {
      "cache_read": "0.2000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.2000000"
    },
    "devstral-2512": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.000000"
    },
    "devstral-medium": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.000000"
    },
    "devstral-small": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.3000000"
    },
    "ernie-4.5-21b-a3b": {
      "cache_read": "0.035000000",
      "cache_write": "0.070000000",
      "input": "0.07000000",
      "output": "0.28000000"
    },
    "ernie-4.5-21b-a3b-thinking": {
      "cache_read": "0.035000000",
      "cache_write": "0.070000000",
      "input": "0.07000000",
      "output": "0.28000000"
    },
    "ernie-4.5-300b-a47b": {
      "cache_read": "0.140000000",
      "cache_write": "0.280000000",
      "input": "0.28000000",
      "output": "1.1000000"
    },
    "ernie-4.5-vl-28b-a3b": {
      "cache_read": "0.070000000",
      "cache_write": "0.140000000",
      "input": "0.14000000",
      "output": "0.56000000"
    },
    "ernie-4.5-vl-424b-a47b": {
      "cache_read": "0.210000000",
      "cache_write": "0.420000000",
      "input": "0.42000000",
      "output": "1.25000000"
    },
    "gemini-2.0-flash-001": {
      "cache_read": "0.025000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.1000000",
      "output": "0.4000000"
    },
    "gemini-2.0-flash-lite-001": {
      "cache_read": "0.0375000000",
      "cache_write": "0.0750000000",
      "input": "0.075000000",
      "output": "0.3000000"
    },
    "gemini-2.5-flash": {
      "cache_read": "0.03000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.3000000",
      "output": "2.5000000"
    },
    "gemini-2.5-flash-image": {
      "cache_read": "0.03000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.3000000",
      "output": "2.5000000"
    },
    "gemini-2.5-flash-lite": {
      "cache_read": "0.01000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.1000000",
      "output": "0.4000000"
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
      "cache_read": "0.01000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.1000000",
      "output": "0.4000000"
    },
    "gemini-2.5-pro": {
      "cache_read": "0.125000000",
      "cache_write": "0.375000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gemini-2.5-pro-preview": {
      "cache_read": "0.125000000",
      "cache_write": "0.375000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gemini-2.5-pro-preview-05-06": {
      "cache_read": "0.125000000",
      "cache_write": "0.375000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gemini-3-flash-preview": {
      "cache_read": "0.05000000",
      "cache_write": "0.08333333333333334000000",
      "input": "0.5000000",
      "output": "3.000000"
    },
    "gemini-3-pro-image-preview": {
      "cache_read": "0.2000000",
      "cache_write": "0.375000000",
      "input": "2.000000",
      "output": "12.000000"
    },
    "gemini-3-pro-preview": {
      "cache_read": "0.2000000",
      "cache_write": "0.375000000",
      "input": "2.000000",
      "output": "12.000000"
    },
    "gemini-3.1-pro-preview": {
      "cache_read": "0.2000000",
      "cache_write": "0.375000000",
      "input": "2.000000",
      "output": "12.000000"
    },
    "gemma-2-27b-it": {
      "cache_read": "0.325000000",
      "cache_write": "0.650000000",
      "input": "0.65000000",
      "output": "0.65000000"
    },
    "gemma-2-9b-it": {
      "cache_read": "0.015000000",
      "cache_write": "0.030000000",
      "input": "0.03000000",
      "output": "0.09000000"
    },
    "gemma-3-12b-it": {
      "cache_read": "0.020000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.13000000"
    },
    "gemma-3-27b-it": {
      "cache_read": "0.02000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.15000000"
    },
    "gemma-3-4b-it": {
      "cache_read": "0.020000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.08000000"
    },
    "gemma-3n-e4b-it": {
      "cache_read": "0.010000000",
      "cache_write": "0.020000000",
      "input": "0.02000000",
      "output": "0.04000000"
    },
    "glm-4-32b": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.1000000"
    },
    "glm-4.5": {
      "cache_read": "0.275000000",
      "cache_write": "0.550000000",
      "input": "0.55000000",
      "output": "2.000000"
    },
    "glm-4.5-air": {
      "cache_read": "0.025000000",
      "cache_write": "0.130000000",
      "input": "0.13000000",
      "output": "0.85000000"
    },
    "glm-4.5v": {
      "cache_read": "0.11000000",
      "cache_write": "0.60000000",
      "input": "0.6000000",
      "output": "1.8000000"
    },
    "glm-4.6": {
      "cache_read": "0.175000000",
      "cache_write": "0.350000000",
      "input": "0.35000000",
      "output": "1.71000000"
    },
    "glm-4.6:exacto": {
      "cache_read": "0.11000000",
      "cache_write": "0.440000000",
      "input": "0.44000000",
      "output": "1.76000000"
    },
    "glm-4.6v": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.9000000"
    },
    "glm-4.7": {
      "cache_read": "0.19000000",
      "cache_write": "0.380000000",
      "input": "0.38000000",
      "output": "1.7000000"
    },
    "glm-4.7-flash": {
      "cache_read": "0.0100000002000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.4000000"
    },
    "glm-5": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "2.55000000"
    },
    "goliath-120b": {
      "cache_read": "1.875000000",
      "cache_write": "3.750000000",
      "input": "3.75000000",
      "output": "7.5000000"
    },
    "gpt-3.5-turbo": {
      "cache_read": "0.25000000",
      "cache_write": "0.50000000",
      "input": "0.5000000",
      "output": "1.5000000"
    },
    "gpt-3.5-turbo-0613": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "2.000000"
    },
    "gpt-3.5-turbo-16k": {
      "cache_read": "1.5000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "4.000000"
    },
    "gpt-3.5-turbo-instruct": {
      "cache_read": "0.75000000",
      "cache_write": "1.50000000",
      "input": "1.5000000",
      "output": "2.000000"
    },
    "gpt-4": {
      "cache_read": "15.000000",
      "cache_write": "30.000000",
      "input": "30.00000",
      "output": "60.00000"
    },
    "gpt-4-0314": {
      "cache_read": "15.000000",
      "cache_write": "30.000000",
      "input": "30.00000",
      "output": "60.00000"
    },
    "gpt-4-1106-preview": {
      "cache_read": "5.000000",
      "cache_write": "10.000000",
      "input": "10.00000",
      "output": "30.00000"
    },
    "gpt-4-turbo": {
      "cache_read": "5.000000",
      "cache_write": "10.000000",
      "input": "10.00000",
      "output": "30.00000"
    },
    "gpt-4-turbo-preview": {
      "cache_read": "5.000000",
      "cache_write": "10.000000",
      "input": "10.00000",
      "output": "30.00000"
    },
    "gpt-4.1": {
      "cache_read": "0.5000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "gpt-4.1-mini": {
      "cache_read": "0.1000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.6000000"
    },
    "gpt-4.1-nano": {
      "cache_read": "0.025000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.4000000"
    },
    "gpt-4o": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-4o-2024-05-13": {
      "cache_read": "2.5000000",
      "cache_write": "5.0000000",
      "input": "5.000000",
      "output": "15.000000"
    },
    "gpt-4o-2024-08-06": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-4o-2024-11-20": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-4o-audio-preview": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-4o-mini": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "gpt-4o-mini-2024-07-18": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "gpt-4o-mini-search-preview": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "gpt-4o-search-preview": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-4o:extended": {
      "cache_read": "3.0000000",
      "cache_write": "6.0000000",
      "input": "6.000000",
      "output": "18.000000"
    },
    "gpt-5": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5-chat": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5-codex": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5-image": {
      "cache_read": "1.25000000",
      "cache_write": "10.000000",
      "input": "10.00000",
      "output": "10.00000"
    },
    "gpt-5-image-mini": {
      "cache_read": "0.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "2.000000"
    },
    "gpt-5-mini": {
      "cache_read": "0.025000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "2.000000"
    },
    "gpt-5-nano": {
      "cache_read": "0.005000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.4000000"
    },
    "gpt-5-pro": {
      "cache_read": "7.5000000",
      "cache_write": "15.0000000",
      "input": "15.000000",
      "output": "120.00000"
    },
    "gpt-5.1": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5.1-chat": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5.1-codex": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5.1-codex-max": {
      "cache_read": "0.125000000",
      "cache_write": "1.250000000",
      "input": "1.25000000",
      "output": "10.00000"
    },
    "gpt-5.1-codex-mini": {
      "cache_read": "0.025000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "2.000000"
    },
    "gpt-5.2": {
      "cache_read": "0.175000000",
      "cache_write": "1.750000000",
      "input": "1.75000000",
      "output": "14.000000"
    },
    "gpt-5.2-chat": {
      "cache_read": "0.175000000",
      "cache_write": "1.750000000",
      "input": "1.75000000",
      "output": "14.000000"
    },
    "gpt-5.2-codex": {
      "cache_read": "0.175000000",
      "cache_write": "1.750000000",
      "input": "1.75000000",
      "output": "14.000000"
    },
    "gpt-5.2-pro": {
      "cache_read": "10.5000000",
      "cache_write": "21.0000000",
      "input": "21.000000",
      "output": "168.000000"
    },
    "gpt-audio": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "gpt-audio-mini": {
      "cache_read": "0.30000000",
      "cache_write": "0.60000000",
      "input": "0.6000000",
      "output": "2.4000000"
    },
    "gpt-oss-120b": {
      "cache_read": "0.0195000000",
      "cache_write": "0.0390000000",
      "input": "0.039000000",
      "output": "0.19000000"
    },
    "gpt-oss-120b:exacto": {
      "cache_read": "0.0195000000",
      "cache_write": "0.0390000000",
      "input": "0.039000000",
      "output": "0.19000000"
    },
    "gpt-oss-20b": {
      "cache_read": "0.015000000",
      "cache_write": "0.030000000",
      "input": "0.03000000",
      "output": "0.14000000"
    },
    "gpt-oss-safeguard-20b": {
      "cache_read": "0.037000000",
      "cache_write": "0.0750000000",
      "input": "0.075000000",
      "output": "0.3000000"
    },
    "granite-4.0-h-micro": {
      "cache_read": "0.0085000000",
      "cache_write": "0.0170000000",
      "input": "0.017000000",
      "output": "0.11000000"
    },
    "grok-3": {
      "cache_read": "0.75000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "grok-3-beta": {
      "cache_read": "0.75000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "grok-3-mini": {
      "cache_read": "0.075000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.5000000"
    },
    "grok-3-mini-beta": {
      "cache_read": "0.075000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.5000000"
    },
    "grok-4": {
      "cache_read": "0.75000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "grok-4-fast": {
      "cache_read": "0.05000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.5000000"
    },
    "grok-4.1-fast": {
      "cache_read": "0.05000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.5000000"
    },
    "grok-code-fast-1": {
      "cache_read": "0.02000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "1.5000000"
    },
    "hermes-2-pro-llama-3-8b": {
      "cache_read": "0.070000000",
      "cache_write": "0.140000000",
      "input": "0.14000000",
      "output": "0.14000000"
    },
    "hermes-3-llama-3.1-405b": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "1.000000"
    },
    "hermes-3-llama-3.1-70b": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "0.3000000"
    },
    "hermes-4-405b": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "3.000000"
    },
    "hermes-4-70b": {
      "cache_read": "0.065000000",
      "cache_write": "0.130000000",
      "input": "0.13000000",
      "output": "0.4000000"
    },
    "hunyuan-a13b-instruct": {
      "cache_read": "0.070000000",
      "cache_write": "0.140000000",
      "input": "0.14000000",
      "output": "0.57000000"
    },
    "inflection-3-pi": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "inflection-3-productivity": {
      "cache_read": "1.25000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "10.00000"
    },
    "intellect-3": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "1.1000000"
    },
    "internvl3-78b": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "jamba-large-1.7": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "kat-coder-pro": {
      "cache_read": "0.0414000000",
      "cache_write": "0.2070000000",
      "input": "0.207000000",
      "output": "0.828000000"
    },
    "kimi-k2": {
      "cache_read": "0.25000000",
      "cache_write": "0.50000000",
      "input": "0.5000000",
      "output": "2.4000000"
    },
    "kimi-k2-0905": {
      "cache_read": "0.15000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.000000"
    },
    "kimi-k2-0905:exacto": {
      "cache_read": "0.30000000",
      "cache_write": "0.60000000",
      "input": "0.6000000",
      "output": "2.5000000"
    },
    "kimi-k2-thinking": {
      "cache_read": "0.141000000",
      "cache_write": "0.470000000",
      "input": "0.47000000",
      "output": "2.000000"
    },
    "kimi-k2.5": {
      "cache_read": "0.115000000",
      "cache_write": "0.230000000",
      "input": "0.23000000",
      "output": "3.000000"
    },
    "l3-euryale-70b": {
      "cache_read": "0.740000000",
      "cache_write": "1.480000000",
      "input": "1.48000000",
      "output": "1.48000000"
    },
    "l3-lunaris-8b": {
      "cache_read": "0.020000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.05000000"
    },
    "l3.1-70b-hanami-x1": {
      "cache_read": "1.5000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "3.000000"
    },
    "l3.1-euryale-70b": {
      "cache_read": "0.325000000",
      "cache_write": "0.650000000",
      "input": "0.65000000",
      "output": "0.75000000"
    },
    "l3.3-euryale-70b": {
      "cache_read": "0.325000000",
      "cache_write": "0.650000000",
      "input": "0.65000000",
      "output": "0.75000000"
    },
    "lfm-2.2-6b": {
      "cache_read": "0.005000000",
      "cache_write": "0.010000000",
      "input": "0.01000000",
      "output": "0.02000000"
    },
    "lfm2-8b-a1b": {
      "cache_read": "0.005000000",
      "cache_write": "0.010000000",
      "input": "0.01000000",
      "output": "0.02000000"
    },
    "llama-3-70b-instruct": {
      "cache_read": "0.255000000",
      "cache_write": "0.510000000",
      "input": "0.51000000",
      "output": "0.74000000"
    },
    "llama-3-8b-instruct": {
      "cache_read": "0.015000000",
      "cache_write": "0.030000000",
      "input": "0.03000000",
      "output": "0.04000000"
    },
    "llama-3.1-405b": {
      "cache_read": "2.0000000",
      "cache_write": "4.0000000",
      "input": "4.000000",
      "output": "4.000000"
    },
    "llama-3.1-405b-instruct": {
      "cache_read": "2.0000000",
      "cache_write": "4.0000000",
      "input": "4.000000",
      "output": "4.000000"
    },
    "llama-3.1-70b-instruct": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "0.4000000"
    },
    "llama-3.1-8b-instruct": {
      "cache_read": "0.010000000",
      "cache_write": "0.020000000",
      "input": "0.02000000",
      "output": "0.05000000"
    },
    "llama-3.1-lumimaid-8b": {
      "cache_read": "0.045000000",
      "cache_write": "0.090000000",
      "input": "0.09000000",
      "output": "0.6000000"
    },
    "llama-3.1-nemotron-70b-instruct": {
      "cache_read": "0.60000000",
      "cache_write": "1.20000000",
      "input": "1.2000000",
      "output": "1.2000000"
    },
    "llama-3.1-nemotron-ultra-253b-v1": {
      "cache_read": "0.30000000",
      "cache_write": "0.60000000",
      "input": "0.6000000",
      "output": "1.8000000"
    },
    "llama-3.2-11b-vision-instruct": {
      "cache_read": "0.0245000000",
      "cache_write": "0.0490000000",
      "input": "0.049000000",
      "output": "0.049000000"
    },
    "llama-3.2-1b-instruct": {
      "cache_read": "0.0135000000",
      "cache_write": "0.0270000000",
      "input": "0.027000000",
      "output": "0.2000000"
    },
    "llama-3.2-3b-instruct": {
      "cache_read": "0.010000000",
      "cache_write": "0.020000000",
      "input": "0.02000000",
      "output": "0.02000000"
    },
    "llama-3.3-70b-instruct": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.32000000"
    },
    "llama-3.3-nemotron-super-49b-v1.5": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.4000000"
    },
    "llama-4-maverick": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.6000000"
    },
    "llama-4-scout": {
      "cache_read": "0.040000000",
      "cache_write": "0.080000000",
      "input": "0.08000000",
      "output": "0.3000000"
    },
    "llama-guard-2-8b": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "llama-guard-3-8b": {
      "cache_read": "0.010000000",
      "cache_write": "0.020000000",
      "input": "0.02000000",
      "output": "0.06000000"
    },
    "llama-guard-4-12b": {
      "cache_read": "0.090000000",
      "cache_write": "0.180000000",
      "input": "0.18000000",
      "output": "0.18000000"
    },
    "llemma_7b": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "1.2000000"
    },
    "longcat-flash-chat": {
      "cache_read": "0.2000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.8000000"
    },
    "maestro-reasoning": {
      "cache_read": "0.45000000",
      "cache_write": "0.90000000",
      "input": "0.9000000",
      "output": "3.3000000"
    },
    "magnum-v4-72b": {
      "cache_read": "1.5000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "5.000000"
    },
    "mercury": {
      "cache_read": "0.125000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "1.000000"
    },
    "mercury-coder": {
      "cache_read": "0.125000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "1.000000"
    },
    "mimo-v2-flash": {
      "cache_read": "0.045000000",
      "cache_write": "0.090000000",
      "input": "0.09000000",
      "output": "0.29000000"
    },
    "minimax-01": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "1.1000000"
    },
    "minimax-m1": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.2000000"
    },
    "minimax-m2": {
      "cache_read": "0.03000000",
      "cache_write": "0.2550000000",
      "input": "0.255000000",
      "output": "1.000000"
    },
    "minimax-m2-her": {
      "cache_read": "0.03000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "1.2000000"
    },
    "minimax-m2.1": {
      "cache_read": "0.0299999997000000",
      "cache_write": "0.270000000",
      "input": "0.27000000",
      "output": "0.95000000"
    },
    "minimax-m2.5": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "1.1000000"
    },
    "ministral-14b-2512": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "ministral-3b-2512": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.1000000"
    },
    "ministral-8b-2512": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.15000000"
    },
    "mistral-7b-instruct": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "mistral-7b-instruct-v0.1": {
      "cache_read": "0.055000000",
      "cache_write": "0.110000000",
      "input": "0.11000000",
      "output": "0.19000000"
    },
    "mistral-7b-instruct-v0.2": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "mistral-7b-instruct-v0.3": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "mistral-large": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "6.000000"
    },
    "mistral-large-2407": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "6.000000"
    },
    "mistral-large-2411": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "6.000000"
    },
    "mistral-large-2512": {
      "cache_read": "0.25000000",
      "cache_write": "0.50000000",
      "input": "0.5000000",
      "output": "1.5000000"
    },
    "mistral-medium-3": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.000000"
    },
    "mistral-medium-3.1": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.000000"
    },
    "mistral-nemo": {
      "cache_read": "0.010000000",
      "cache_write": "0.020000000",
      "input": "0.02000000",
      "output": "0.04000000"
    },
    "mistral-saba": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.6000000"
    },
    "mistral-small-24b-instruct-2501": {
      "cache_read": "0.025000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.08000000"
    },
    "mistral-small-3.1-24b-instruct": {
      "cache_read": "0.175000000",
      "cache_write": "0.350000000",
      "input": "0.35000000",
      "output": "0.56000000"
    },
    "mistral-small-3.2-24b-instruct": {
      "cache_read": "0.03000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.18000000"
    },
    "mistral-small-creative": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.3000000"
    },
    "mixtral-8x22b-instruct": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "6.000000"
    },
    "mixtral-8x7b-instruct": {
      "cache_read": "0.270000000",
      "cache_write": "0.540000000",
      "input": "0.54000000",
      "output": "0.54000000"
    },
    "molmo-2-8b": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "morph-v3-fast": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "1.2000000"
    },
    "morph-v3-large": {
      "cache_read": "0.45000000",
      "cache_write": "0.90000000",
      "input": "0.9000000",
      "output": "1.9000000"
    },
    "mythomax-l2-13b": {
      "cache_read": "0.030000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.06000000"
    },
    "nemotron-3-nano-30b-a3b": {
      "cache_read": "0.025000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.2000000"
    },
    "nemotron-nano-12b-v2-vl": {
      "cache_read": "0.035000000",
      "cache_write": "0.070000000",
      "input": "0.07000000",
      "output": "0.2000000"
    },
    "nemotron-nano-9b-v2": {
      "cache_read": "0.020000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.16000000"
    },
    "noromaid-20b": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "1.75000000"
    },
    "nova-2-lite-v1": {
      "cache_read": "0.15000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "2.5000000"
    },
    "nova-lite-v1": {
      "cache_read": "0.030000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.24000000"
    },
    "nova-micro-v1": {
      "cache_read": "0.0175000000",
      "cache_write": "0.0350000000",
      "input": "0.035000000",
      "output": "0.14000000"
    },
    "nova-premier-v1": {
      "cache_read": "0.625000000",
      "cache_write": "2.50000000",
      "input": "2.5000000",
      "output": "12.5000000"
    },
    "nova-pro-v1": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "3.2000000"
    },
    "o1": {
      "cache_read": "7.5000000",
      "cache_write": "15.0000000",
      "input": "15.000000",
      "output": "60.00000"
    },
    "o1-pro": {
      "cache_read": "75.000000",
      "cache_write": "150.000000",
      "input": "150.00000",
      "output": "600.0000"
    },
    "o3": {
      "cache_read": "0.5000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "o3-deep-research": {
      "cache_read": "2.5000000",
      "cache_write": "10.000000",
      "input": "10.00000",
      "output": "40.00000"
    },
    "o3-mini": {
      "cache_read": "0.55000000",
      "cache_write": "1.10000000",
      "input": "1.1000000",
      "output": "4.4000000"
    },
    "o3-mini-high": {
      "cache_read": "0.55000000",
      "cache_write": "1.10000000",
      "input": "1.1000000",
      "output": "4.4000000"
    },
    "o3-pro": {
      "cache_read": "10.000000",
      "cache_write": "20.000000",
      "input": "20.00000",
      "output": "80.00000"
    },
    "o4-mini": {
      "cache_read": "0.275000000",
      "cache_write": "1.10000000",
      "input": "1.1000000",
      "output": "4.4000000"
    },
    "o4-mini-deep-research": {
      "cache_read": "0.5000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "o4-mini-high": {
      "cache_read": "0.275000000",
      "cache_write": "1.10000000",
      "input": "1.1000000",
      "output": "4.4000000"
    },
    "olmo-2-0325-32b-instruct": {
      "cache_read": "0.025000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.2000000"
    },
    "olmo-3-32b-think": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.5000000"
    },
    "olmo-3-7b-instruct": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.2000000"
    },
    "olmo-3-7b-think": {
      "cache_read": "0.060000000",
      "cache_write": "0.120000000",
      "input": "0.12000000",
      "output": "0.2000000"
    },
    "olmo-3.1-32b-instruct": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.6000000"
    },
    "olmo-3.1-32b-think": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.5000000"
    },
    "palmyra-x5": {
      "cache_read": "0.30000000",
      "cache_write": "0.60000000",
      "input": "0.6000000",
      "output": "6.000000"
    },
    "phi-4": {
      "cache_read": "0.030000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.14000000"
    },
    "pixtral-large-2411": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "6.000000"
    },
    "qwen-2.5-72b-instruct": {
      "cache_read": "0.060000000",
      "cache_write": "0.120000000",
      "input": "0.12000000",
      "output": "0.39000000"
    },
    "qwen-2.5-7b-instruct": {
      "cache_read": "0.020000000",
      "cache_write": "0.040000000",
      "input": "0.04000000",
      "output": "0.1000000"
    },
    "qwen-2.5-coder-32b-instruct": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "qwen-2.5-vl-7b-instruct": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.2000000"
    },
    "qwen-max": {
      "cache_read": "0.32000000",
      "cache_write": "1.60000000",
      "input": "1.6000000",
      "output": "6.4000000"
    },
    "qwen-plus": {
      "cache_read": "0.08000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.2000000"
    },
    "qwen-plus-2025-07-28": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.2000000"
    },
    "qwen-plus-2025-07-28:thinking": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "1.2000000"
    },
    "qwen-turbo": {
      "cache_read": "0.01000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.2000000"
    },
    "qwen-vl-max": {
      "cache_read": "0.40000000",
      "cache_write": "0.80000000",
      "input": "0.8000000",
      "output": "3.2000000"
    },
    "qwen-vl-plus": {
      "cache_read": "0.042000000",
      "cache_write": "0.210000000",
      "input": "0.21000000",
      "output": "0.63000000"
    },
    "qwen2.5-coder-7b-instruct": {
      "cache_read": "0.015000000",
      "cache_write": "0.030000000",
      "input": "0.03000000",
      "output": "0.09000000"
    },
    "qwen2.5-vl-32b-instruct": {
      "cache_read": "0.10000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.6000000"
    },
    "qwen2.5-vl-72b-instruct": {
      "cache_read": "0.125000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "0.75000000"
    },
    "qwen3-14b": {
      "cache_read": "0.030000000",
      "cache_write": "0.060000000",
      "input": "0.06000000",
      "output": "0.24000000"
    },
    "qwen3-235b-a22b": {
      "cache_read": "0.2275000000",
      "cache_write": "0.4550000000",
      "input": "0.455000000",
      "output": "1.82000000"
    },
    "qwen3-235b-a22b-2507": {
      "cache_read": "0.0355000000",
      "cache_write": "0.0710000000",
      "input": "0.071000000",
      "output": "0.1000000"
    },
    "qwen3-30b-a3b": {
      "cache_read": "0.040000000",
      "cache_write": "0.080000000",
      "input": "0.08000000",
      "output": "0.28000000"
    },
    "qwen3-30b-a3b-instruct-2507": {
      "cache_read": "0.045000000",
      "cache_write": "0.090000000",
      "input": "0.09000000",
      "output": "0.3000000"
    },
    "qwen3-30b-a3b-thinking-2507": {
      "cache_read": "0.0255000000",
      "cache_write": "0.0510000000",
      "input": "0.051000000",
      "output": "0.34000000"
    },
    "qwen3-32b": {
      "cache_read": "0.04000000",
      "cache_write": "0.080000000",
      "input": "0.08000000",
      "output": "0.24000000"
    },
    "qwen3-8b": {
      "cache_read": "0.05000000",
      "cache_write": "0.050000000",
      "input": "0.05000000",
      "output": "0.4000000"
    },
    "qwen3-coder": {
      "cache_read": "0.022000000",
      "cache_write": "0.220000000",
      "input": "0.22000000",
      "output": "1.000000"
    },
    "qwen3-coder-30b-a3b-instruct": {
      "cache_read": "0.035000000",
      "cache_write": "0.070000000",
      "input": "0.07000000",
      "output": "0.27000000"
    },
    "qwen3-coder-flash": {
      "cache_read": "0.06000000",
      "cache_write": "0.30000000",
      "input": "0.3000000",
      "output": "1.5000000"
    },
    "qwen3-coder-next": {
      "cache_read": "0.06000000",
      "cache_write": "0.120000000",
      "input": "0.12000000",
      "output": "0.75000000"
    },
    "qwen3-coder-plus": {
      "cache_read": "0.2000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "5.000000"
    },
    "qwen3-coder:exacto": {
      "cache_read": "0.022000000",
      "cache_write": "0.220000000",
      "input": "0.22000000",
      "output": "1.8000000"
    },
    "qwen3-max": {
      "cache_read": "0.24000000",
      "cache_write": "1.20000000",
      "input": "1.2000000",
      "output": "6.000000"
    },
    "qwen3-max-thinking": {
      "cache_read": "0.60000000",
      "cache_write": "1.20000000",
      "input": "1.2000000",
      "output": "6.000000"
    },
    "qwen3-next-80b-a3b-instruct": {
      "cache_read": "0.045000000",
      "cache_write": "0.090000000",
      "input": "0.09000000",
      "output": "1.1000000"
    },
    "qwen3-next-80b-a3b-thinking": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "1.2000000"
    },
    "qwen3-vl-235b-a22b-instruct": {
      "cache_read": "0.11000000",
      "cache_write": "0.20000000",
      "input": "0.2000000",
      "output": "0.88000000"
    },
    "qwen3-vl-30b-a3b-instruct": {
      "cache_read": "0.065000000",
      "cache_write": "0.130000000",
      "input": "0.13000000",
      "output": "0.52000000"
    },
    "qwen3-vl-32b-instruct": {
      "cache_read": "0.0520000000",
      "cache_write": "0.1040000000",
      "input": "0.104000000",
      "output": "0.416000000"
    },
    "qwen3-vl-8b-instruct": {
      "cache_read": "0.040000000",
      "cache_write": "0.080000000",
      "input": "0.08000000",
      "output": "0.5000000"
    },
    "qwen3-vl-8b-thinking": {
      "cache_read": "0.0585000000",
      "cache_write": "0.1170000000",
      "input": "0.117000000",
      "output": "1.365000000"
    },
    "qwen3.5-397b-a17b": {
      "cache_read": "0.15000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "1.000000"
    },
    "qwen3.5-plus-02-15": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "2.4000000"
    },
    "qwq-32b": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.4000000"
    },
    "relace-apply-3": {
      "cache_read": "0.425000000",
      "cache_write": "0.850000000",
      "input": "0.85000000",
      "output": "1.25000000"
    },
    "relace-search": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "3.000000"
    },
    "remm-slerp-l2-13b": {
      "cache_read": "0.225000000",
      "cache_write": "0.450000000",
      "input": "0.45000000",
      "output": "0.65000000"
    },
    "rnj-1-instruct": {
      "cache_read": "0.075000000",
      "cache_write": "0.150000000",
      "input": "0.15000000",
      "output": "0.15000000"
    },
    "rocinante-12b": {
      "cache_read": "0.085000000",
      "cache_write": "0.170000000",
      "input": "0.17000000",
      "output": "0.43000000"
    },
    "router": {
      "cache_read": "0.425000000",
      "cache_write": "0.850000000",
      "input": "0.85000000",
      "output": "3.4000000"
    },
    "seed-1.6": {
      "cache_read": "0.125000000",
      "cache_write": "0.250000000",
      "input": "0.25000000",
      "output": "2.000000"
    },
    "seed-1.6-flash": {
      "cache_read": "0.0375000000",
      "cache_write": "0.0750000000",
      "input": "0.075000000",
      "output": "0.3000000"
    },
    "skyfall-36b-v2": {
      "cache_read": "0.275000000",
      "cache_write": "0.550000000",
      "input": "0.55000000",
      "output": "0.8000000"
    },
    "sonar": {
      "cache_read": "0.5000000",
      "cache_write": "1.0000000",
      "input": "1.000000",
      "output": "1.000000"
    },
    "sonar-deep-research": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "sonar-pro": {
      "cache_read": "1.5000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "sonar-pro-search": {
      "cache_read": "1.5000000",
      "cache_write": "3.0000000",
      "input": "3.000000",
      "output": "15.000000"
    },
    "sonar-reasoning-pro": {
      "cache_read": "1.0000000",
      "cache_write": "2.0000000",
      "input": "2.000000",
      "output": "8.000000"
    },
    "sorcererlm-8x22b": {
      "cache_read": "2.25000000",
      "cache_write": "4.50000000",
      "input": "4.5000000",
      "output": "4.5000000"
    },
    "spotlight": {
      "cache_read": "0.090000000",
      "cache_write": "0.180000000",
      "input": "0.18000000",
      "output": "0.18000000"
    },
    "step-3.5-flash": {
      "cache_read": "0.02000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.3000000"
    },
    "tongyi-deepresearch-30b-a3b": {
      "cache_read": "0.09000000",
      "cache_write": "0.090000000",
      "input": "0.09000000",
      "output": "0.45000000"
    },
    "trinity-mini": {
      "cache_read": "0.0225000000",
      "cache_write": "0.0450000000",
      "input": "0.045000000",
      "output": "0.15000000"
    },
    "ui-tars-1.5-7b": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.2000000"
    },
    "unslopnemo-12b": {
      "cache_read": "0.20000000",
      "cache_write": "0.40000000",
      "input": "0.4000000",
      "output": "0.4000000"
    },
    "virtuoso-large": {
      "cache_read": "0.375000000",
      "cache_write": "0.750000000",
      "input": "0.75000000",
      "output": "1.2000000"
    },
    "voxtral-small-24b-2507": {
      "cache_read": "0.05000000",
      "cache_write": "0.10000000",
      "input": "0.1000000",
      "output": "0.3000000"
    },
    "weaver": {
      "cache_read": "0.375000000",
      "cache_write": "0.750000000",
      "input": "0.75000000",
      "output": "1.000000"
    },
    "wizardlm-2-8x22b": {
      "cache_read": "0.310000000",
      "cache_write": "0.620000000",
      "input": "0.62000000",
      "output": "0.62000000"
    }
  },
  "providers": {
    "gpt-5.3-codex": "openai",
    "aion-2.0": "aion-labs",
    "gemini-3.1-pro-preview": "google",
    "claude-sonnet-4.6": "anthropic",
    "qwen3.5-plus-02-15": "qwen",
    "qwen3.5-397b-a17b": "qwen",
    "minimax-m2.5": "minimax",
    "glm-5": "z-ai",
    "qwen3-max-thinking": "qwen",
    "claude-opus-4.6": "anthropic",
    "qwen3-coder-next": "qwen",
    "step-3.5-flash": "stepfun",
    "kimi-k2.5": "moonshotai",
    "minimax-m2-her": "minimax",
    "palmyra-x5": "writer",
    "gpt-audio": "openai",
    "gpt-audio-mini": "openai",
    "glm-4.7-flash": "z-ai",
    "gpt-5.2-codex": "openai",
    "molmo-2-8b": "allenai",
    "olmo-3.1-32b-instruct": "allenai",
    "seed-1.6-flash": "bytedance-seed",
    "seed-1.6": "bytedance-seed",
    "minimax-m2.1": "minimax",
    "glm-4.7": "z-ai",
    "gemini-3-flash-preview": "google",
    "mistral-small-creative": "mistralai",
    "olmo-3.1-32b-think": "allenai",
    "mimo-v2-flash": "xiaomi",
    "nemotron-3-nano-30b-a3b": "nvidia",
    "gpt-5.2-chat": "openai",
    "gpt-5.2-pro": "openai",
    "gpt-5.2": "openai",
    "devstral-2512": "mistralai",
    "relace-search": "relace",
    "glm-4.6v": "z-ai",
    "deepseek-v3.1-nex-n1": "nex-agi",
    "rnj-1-instruct": "essentialai",
    "bodybuilder": "openrouter",
    "gpt-5.1-codex-max": "openai",
    "nova-2-lite-v1": "amazon",
    "ministral-14b-2512": "mistralai",
    "ministral-8b-2512": "mistralai",
    "ministral-3b-2512": "mistralai",
    "mistral-large-2512": "mistralai",
    "trinity-mini": "arcee-ai",
    "deepseek-v3.2-speciale": "deepseek",
    "deepseek-v3.2": "deepseek",
    "intellect-3": "prime-intellect",
    "claude-opus-4.5": "anthropic",
    "olmo-3-32b-think": "allenai",
    "olmo-3-7b-instruct": "allenai",
    "olmo-3-7b-think": "allenai",
    "gemini-3-pro-image-preview": "google",
    "grok-4.1-fast": "x-ai",
    "gemini-3-pro-preview": "google",
    "cogito-v2.1-671b": "deepcogito",
    "gpt-5.1": "openai",
    "gpt-5.1-chat": "openai",
    "gpt-5.1-codex": "openai",
    "gpt-5.1-codex-mini": "openai",
    "kat-coder-pro": "kwaipilot",
    "kimi-k2-thinking": "moonshotai",
    "nova-premier-v1": "amazon",
    "sonar-pro-search": "perplexity",
    "voxtral-small-24b-2507": "mistralai",
    "gpt-oss-safeguard-20b": "openai",
    "nemotron-nano-12b-v2-vl": "nvidia",
    "minimax-m2": "minimax",
    "qwen3-vl-32b-instruct": "qwen",
    "lfm2-8b-a1b": "liquid",
    "lfm-2.2-6b": "liquid",
    "granite-4.0-h-micro": "ibm-granite",
    "gpt-5-image-mini": "openai",
    "claude-haiku-4.5": "anthropic",
    "qwen3-vl-8b-thinking": "qwen",
    "qwen3-vl-8b-instruct": "qwen",
    "gpt-5-image": "openai",
    "o3-deep-research": "openai",
    "o4-mini-deep-research": "openai",
    "llama-3.3-nemotron-super-49b-v1.5": "nvidia",
    "ernie-4.5-21b-a3b-thinking": "baidu",
    "gemini-2.5-flash-image": "google",
    "qwen3-vl-30b-a3b-instruct": "qwen",
    "gpt-5-pro": "openai",
    "glm-4.6": "z-ai",
    "glm-4.6:exacto": "z-ai",
    "claude-sonnet-4.5": "anthropic",
    "deepseek-v3.2-exp": "deepseek",
    "cydonia-24b-v4.1": "thedrummer",
    "relace-apply-3": "relace",
    "gemini-2.5-flash-lite-preview-09-2025": "google",
    "qwen3-vl-235b-a22b-instruct": "qwen",
    "qwen3-max": "qwen",
    "qwen3-coder-plus": "qwen",
    "gpt-5-codex": "openai",
    "deepseek-v3.1-terminus:exacto": "deepseek",
    "deepseek-v3.1-terminus": "deepseek",
    "grok-4-fast": "x-ai",
    "tongyi-deepresearch-30b-a3b": "alibaba",
    "qwen3-coder-flash": "qwen",
    "internvl3-78b": "opengvlab",
    "qwen3-next-80b-a3b-thinking": "qwen",
    "qwen3-next-80b-a3b-instruct": "qwen",
    "longcat-flash-chat": "meituan",
    "qwen-plus-2025-07-28": "qwen",
    "qwen-plus-2025-07-28:thinking": "qwen",
    "nemotron-nano-9b-v2": "nvidia",
    "kimi-k2-0905": "moonshotai",
    "kimi-k2-0905:exacto": "moonshotai",
    "qwen3-30b-a3b-thinking-2507": "qwen",
    "grok-code-fast-1": "x-ai",
    "hermes-4-70b": "nousresearch",
    "hermes-4-405b": "nousresearch",
    "deepseek-chat-v3.1": "deepseek",
    "gpt-4o-audio-preview": "openai",
    "mistral-medium-3.1": "mistralai",
    "ernie-4.5-21b-a3b": "baidu",
    "ernie-4.5-vl-28b-a3b": "baidu",
    "glm-4.5v": "z-ai",
    "jamba-large-1.7": "ai21",
    "gpt-5-chat": "openai",
    "gpt-5": "openai",
    "gpt-5-mini": "openai",
    "gpt-5-nano": "openai",
    "gpt-oss-120b": "openai",
    "gpt-oss-120b:exacto": "openai",
    "gpt-oss-20b": "openai",
    "claude-opus-4.1": "anthropic",
    "codestral-2508": "mistralai",
    "qwen3-coder-30b-a3b-instruct": "qwen",
    "qwen3-30b-a3b-instruct-2507": "qwen",
    "glm-4.5": "z-ai",
    "glm-4.5-air": "z-ai",
    "glm-4-32b": "z-ai",
    "qwen3-coder": "qwen",
    "qwen3-coder:exacto": "qwen",
    "ui-tars-1.5-7b": "bytedance",
    "gemini-2.5-flash-lite": "google",
    "qwen3-235b-a22b-2507": "qwen",
    "router": "switchpoint",
    "kimi-k2": "moonshotai",
    "devstral-medium": "mistralai",
    "devstral-small": "mistralai",
    "grok-4": "x-ai",
    "hunyuan-a13b-instruct": "tencent",
    "deepseek-r1t2-chimera": "tngtech",
    "morph-v3-large": "morph",
    "morph-v3-fast": "morph",
    "ernie-4.5-vl-424b-a47b": "baidu",
    "ernie-4.5-300b-a47b": "baidu",
    "mercury": "inception",
    "mistral-small-3.2-24b-instruct": "mistralai",
    "minimax-m1": "minimax",
    "gemini-2.5-flash": "google",
    "gemini-2.5-pro": "google",
    "o3-pro": "openai",
    "grok-3-mini": "x-ai",
    "grok-3": "x-ai",
    "gemini-2.5-pro-preview": "google",
    "deepseek-r1-0528": "deepseek",
    "claude-opus-4": "anthropic",
    "claude-sonnet-4": "anthropic",
    "gemma-3n-e4b-it": "google",
    "mistral-medium-3": "mistralai",
    "gemini-2.5-pro-preview-05-06": "google",
    "spotlight": "arcee-ai",
    "maestro-reasoning": "arcee-ai",
    "virtuoso-large": "arcee-ai",
    "coder-large": "arcee-ai",
    "mercury-coder": "inception",
    "llama-guard-4-12b": "meta-llama",
    "qwen3-30b-a3b": "qwen",
    "qwen3-8b": "qwen",
    "qwen3-14b": "qwen",
    "qwen3-32b": "qwen",
    "qwen3-235b-a22b": "qwen",
    "o4-mini-high": "openai",
    "o3": "openai",
    "o4-mini": "openai",
    "qwen2.5-coder-7b-instruct": "qwen",
    "gpt-4.1": "openai",
    "gpt-4.1-mini": "openai",
    "gpt-4.1-nano": "openai",
    "llemma_7b": "eleutherai",
    "codellama-7b-instruct-solidity": "alfredpros",
    "grok-3-mini-beta": "x-ai",
    "grok-3-beta": "x-ai",
    "llama-4-maverick": "meta-llama",
    "llama-4-scout": "meta-llama",
    "qwen2.5-vl-32b-instruct": "qwen",
    "deepseek-chat-v3-0324": "deepseek",
    "o1-pro": "openai",
    "mistral-small-3.1-24b-instruct": "mistralai",
    "olmo-2-0325-32b-instruct": "allenai",
    "gemma-3-4b-it": "google",
    "gemma-3-12b-it": "google",
    "command-a": "cohere",
    "gpt-4o-mini-search-preview": "openai",
    "gpt-4o-search-preview": "openai",
    "gemma-3-27b-it": "google",
    "skyfall-36b-v2": "thedrummer",
    "sonar-reasoning-pro": "perplexity",
    "sonar-pro": "perplexity",
    "sonar-deep-research": "perplexity",
    "qwq-32b": "qwen",
    "gemini-2.0-flash-lite-001": "google",
    "claude-3.7-sonnet": "anthropic",
    "claude-3.7-sonnet:thinking": "anthropic",
    "mistral-saba": "mistralai",
    "llama-guard-3-8b": "meta-llama",
    "o3-mini-high": "openai",
    "gemini-2.0-flash-001": "google",
    "qwen-vl-plus": "qwen",
    "aion-1.0": "aion-labs",
    "aion-1.0-mini": "aion-labs",
    "aion-rp-llama-3.1-8b": "aion-labs",
    "qwen-vl-max": "qwen",
    "qwen-turbo": "qwen",
    "qwen2.5-vl-72b-instruct": "qwen",
    "qwen-plus": "qwen",
    "qwen-max": "qwen",
    "o3-mini": "openai",
    "mistral-small-24b-instruct-2501": "mistralai",
    "deepseek-r1-distill-qwen-32b": "deepseek",
    "sonar": "perplexity",
    "deepseek-r1-distill-llama-70b": "deepseek",
    "deepseek-r1": "deepseek",
    "minimax-01": "minimax",
    "phi-4": "microsoft",
    "l3.1-70b-hanami-x1": "sao10k",
    "deepseek-chat": "deepseek",
    "l3.3-euryale-70b": "sao10k",
    "o1": "openai",
    "command-r7b-12-2024": "cohere",
    "llama-3.3-70b-instruct": "meta-llama",
    "nova-lite-v1": "amazon",
    "nova-micro-v1": "amazon",
    "nova-pro-v1": "amazon",
    "gpt-4o-2024-11-20": "openai",
    "mistral-large-2411": "mistralai",
    "mistral-large-2407": "mistralai",
    "pixtral-large-2411": "mistralai",
    "qwen-2.5-coder-32b-instruct": "qwen",
    "sorcererlm-8x22b": "raifle",
    "unslopnemo-12b": "thedrummer",
    "claude-3.5-haiku": "anthropic",
    "magnum-v4-72b": "anthracite-org",
    "claude-3.5-sonnet": "anthropic",
    "qwen-2.5-7b-instruct": "qwen",
    "llama-3.1-nemotron-70b-instruct": "nvidia",
    "inflection-3-pi": "inflection",
    "inflection-3-productivity": "inflection",
    "rocinante-12b": "thedrummer",
    "llama-3.2-3b-instruct": "meta-llama",
    "llama-3.2-1b-instruct": "meta-llama",
    "llama-3.2-11b-vision-instruct": "meta-llama",
    "qwen-2.5-72b-instruct": "qwen",
    "llama-3.1-lumimaid-8b": "neversleep",
    "command-r-08-2024": "cohere",
    "command-r-plus-08-2024": "cohere",
    "l3.1-euryale-70b": "sao10k",
    "qwen-2.5-vl-7b-instruct": "qwen",
    "hermes-3-llama-3.1-70b": "nousresearch",
    "hermes-3-llama-3.1-405b": "nousresearch",
    "l3-lunaris-8b": "sao10k",
    "gpt-4o-2024-08-06": "openai",
    "llama-3.1-405b": "meta-llama",
    "llama-3.1-8b-instruct": "meta-llama",
    "llama-3.1-405b-instruct": "meta-llama",
    "llama-3.1-70b-instruct": "meta-llama",
    "mistral-nemo": "mistralai",
    "gpt-4o-mini-2024-07-18": "openai",
    "gpt-4o-mini": "openai",
    "gemma-2-27b-it": "google",
    "gemma-2-9b-it": "google",
    "l3-euryale-70b": "sao10k",
    "hermes-2-pro-llama-3-8b": "nousresearch",
    "mistral-7b-instruct": "mistralai",
    "mistral-7b-instruct-v0.3": "mistralai",
    "llama-guard-2-8b": "meta-llama",
    "gpt-4o-2024-05-13": "openai",
    "gpt-4o": "openai",
    "gpt-4o:extended": "openai",
    "llama-3-70b-instruct": "meta-llama",
    "llama-3-8b-instruct": "meta-llama",
    "mixtral-8x22b-instruct": "mistralai",
    "wizardlm-2-8x22b": "microsoft",
    "gpt-4-turbo": "openai",
    "claude-3-haiku": "anthropic",
    "mistral-large": "mistralai",
    "gpt-3.5-turbo-0613": "openai",
    "gpt-4-turbo-preview": "openai",
    "mistral-7b-instruct-v0.2": "mistralai",
    "mixtral-8x7b-instruct": "mistralai",
    "noromaid-20b": "neversleep",
    "goliath-120b": "alpindale",
    "auto": "openrouter",
    "gpt-4-1106-preview": "openai",
    "gpt-3.5-turbo-instruct": "openai",
    "mistral-7b-instruct-v0.1": "mistralai",
    "gpt-3.5-turbo-16k": "openai",
    "weaver": "mancer",
    "remm-slerp-l2-13b": "undi95",
    "mythomax-l2-13b": "gryphe",
    "gpt-4-0314": "openai",
    "gpt-4": "openai",
    "gpt-3.5-turbo": "openai"
  }
}
