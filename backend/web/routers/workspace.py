"""Workspace file browsing endpoints."""

import asyncio
from typing import Annotated, Any

from fastapi import APIRouter, Depends, File, HTTPException, Query, UploadFile
from fastapi.responses import FileResponse

from backend.web.core.dependencies import get_app
from backend.web.services.agent_pool import resolve_thread_sandbox
from backend.web.services.file_channel_service import (
    ensure_thread_file_channel,
    list_channel_files,
    list_thread_file_transfers,
    resolve_download_file,
    save_uploaded_file,
)
from backend.web.utils.helpers import resolve_local_workspace_path
from sandbox.thread_context import set_current_thread_id

router = APIRouter(prefix="/api/threads/{thread_id}/workspace", tags=["workspace"])


@router.get("/list")
async def list_workspace_path(
    thread_id: str,
    path: str | None = Query(default=None),
    app: Annotated[Any, Depends(get_app)] = None,
) -> dict[str, Any]:
    """List files and directories in workspace path."""
    sandbox_type = resolve_thread_sandbox(app, thread_id)
    if sandbox_type == "local":
        from core.filesystem.local_backend import LocalBackend

        backend = LocalBackend()
        target = resolve_local_workspace_path(
            path,
            thread_id=thread_id,
            thread_cwd_map=app.state.thread_cwd,
        )
        result = backend.list_dir(str(target))
        if result.error:
            raise HTTPException(400, result.error)
        return {
            "thread_id": thread_id,
            "path": str(target),
            "entries": [
                {"name": e.name, "is_dir": e.is_dir, "size": e.size, "children_count": e.children_count}
                for e in result.entries
            ],
        }

    # Remote sandbox
    from backend.web.services.agent_pool import get_or_create_agent

    try:
        set_current_thread_id(thread_id)
        agent = await get_or_create_agent(app, sandbox_type, thread_id=thread_id)
    # @@@http_passthrough - preserve policy/validation errors from agent creation
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(503, f"Sandbox agent init failed for {sandbox_type}: {e}") from e

    if not hasattr(agent, "_sandbox"):
        raise HTTPException(400, "Agent has no sandbox")
    if agent._sandbox.name == "local":
        raise HTTPException(400, "Agent has no remote sandbox")

    def _list_remote() -> dict[str, Any]:
        set_current_thread_id(thread_id)
        capability = agent._sandbox.manager.get_sandbox(thread_id)
        target = path or capability._session.terminal.get_state().cwd
        result = capability.fs.list_dir(target)
        if result.error:
            raise RuntimeError(result.error)
        return {
            "path": target,
            "entries": [
                {"name": e.name, "is_dir": e.is_dir, "size": e.size, "children_count": e.children_count}
                for e in result.entries
            ],
        }

    try:
        payload = await asyncio.to_thread(_list_remote)
    # @@@http_passthrough - preserve explicit status from remote capability path
    except HTTPException:
        raise
    except RuntimeError as e:
        raise HTTPException(400, str(e)) from e
    return {"thread_id": thread_id, **payload}


@router.get("/read")
async def read_workspace_file(
    thread_id: str,
    path: str = Query(...),
    app: Annotated[Any, Depends(get_app)] = None,
) -> dict[str, Any]:
    """Read file content from workspace."""
    sandbox_type = resolve_thread_sandbox(app, thread_id)
    if sandbox_type == "local":
        from core.filesystem.local_backend import LocalBackend

        backend = LocalBackend()
        target = resolve_local_workspace_path(
            path,
            thread_id=thread_id,
            thread_cwd_map=app.state.thread_cwd,
        )
        try:
            data = backend.read_file(str(target))
        except Exception as e:
            raise HTTPException(400, str(e)) from e
        return {"thread_id": thread_id, "path": str(target), "content": data.content, "size": data.size}

    # Remote sandbox
    from backend.web.services.agent_pool import get_or_create_agent

    try:
        set_current_thread_id(thread_id)
        agent = await get_or_create_agent(app, sandbox_type, thread_id=thread_id)
    except Exception as e:
        raise HTTPException(503, f"Sandbox agent init failed for {sandbox_type}: {e}") from e

    if not hasattr(agent, "_sandbox"):
        raise HTTPException(400, "Agent has no sandbox")
    if agent._sandbox.name == "local":
        raise HTTPException(400, "Agent has no remote sandbox")

    def _read_remote() -> dict[str, Any]:
        set_current_thread_id(thread_id)
        capability = agent._sandbox.manager.get_sandbox(thread_id)
        data = capability.fs.read_file(path)
        return {"path": path, "content": data.content, "size": data.size}

    try:
        payload = await asyncio.to_thread(_read_remote)
    except Exception as e:
        raise HTTPException(400, str(e)) from e
    return {"thread_id": thread_id, **payload}


@router.get("/channels")
async def get_workspace_channels(thread_id: str) -> dict[str, Any]:
    """Get thread-scoped upload/download channel paths."""
    from backend.web.utils.helpers import load_thread_config

    # @@@workspace-lookup - pass stored workspace_id so ensure is idempotent even if called multiple times
    tc = await asyncio.to_thread(load_thread_config, thread_id)
    workspace_id = tc.workspace_id if tc else None
    payload = await asyncio.to_thread(ensure_thread_file_channel, thread_id, workspace_id=workspace_id)
    return payload


_MAX_UPLOAD_BYTES = 100 * 1024 * 1024  # 100 MB


@router.post("/upload")
async def upload_workspace_file(
    thread_id: str,
    file: UploadFile = File(...),
    channel: str = Query(default="download"),
    path: str | None = Query(default=None),
) -> dict[str, Any]:
    """Upload a file into thread-scoped upload/download channel."""
    if not file.filename and not path:
        raise HTTPException(400, "Missing upload path: provide query path or filename")
    relative_path = path or file.filename or ""
    content = await file.read(_MAX_UPLOAD_BYTES + 1)
    if len(content) > _MAX_UPLOAD_BYTES:
        raise HTTPException(413, f"Upload exceeds {_MAX_UPLOAD_BYTES // (1024 * 1024)} MB limit")
    try:
        payload = await asyncio.to_thread(
            save_uploaded_file,
            thread_id=thread_id,
            channel=channel,
            relative_path=relative_path,
            content=content,
        )
    except ValueError as e:
        raise HTTPException(400, str(e)) from e
    return payload


@router.get("/download")
async def download_workspace_file(
    thread_id: str,
    path: str = Query(...),
    channel: str = Query(default="download"),
) -> FileResponse:
    """Download a file from thread-scoped upload/download channel."""
    try:
        target = await asyncio.to_thread(
            resolve_download_file,
            thread_id=thread_id,
            channel=channel,
            relative_path=path,
        )
    except ValueError as e:
        raise HTTPException(400, str(e)) from e
    except FileNotFoundError as e:
        raise HTTPException(404, str(e)) from e
    return FileResponse(path=str(target), filename=target.name, media_type="application/octet-stream")


@router.get("/channel-files")
async def list_workspace_channel_files(
    thread_id: str,
    channel: str = Query(default="download"),
) -> dict[str, Any]:
    """List files under thread-scoped upload/download channel."""
    try:
        entries = await asyncio.to_thread(
            list_channel_files,
            thread_id=thread_id,
            channel=channel,
        )
    except ValueError as e:
        raise HTTPException(400, str(e)) from e
    return {"thread_id": thread_id, "channel": channel, "entries": entries}


@router.get("/transfers")
async def list_workspace_transfers(
    thread_id: str,
    limit: int = Query(default=100, ge=1, le=500),
) -> dict[str, Any]:
    """List thread file transfer records from SQLite."""
    entries = await asyncio.to_thread(list_thread_file_transfers, thread_id=thread_id, limit=limit)
    return {"thread_id": thread_id, "entries": entries}
